{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: ---------------------------\n",
      "COMET INFO: Comet.ml Experiment Summary\n",
      "COMET INFO: ---------------------------\n",
      "COMET INFO:   Data:\n",
      "COMET INFO:     display_summary_level : 1\n",
      "COMET INFO:     url                   : https://www.comet.ml/tci/igtc-project/91a927c820964d19882951529a0454cc\n",
      "COMET INFO:   Uploads:\n",
      "COMET INFO:     environment details      : 1\n",
      "COMET INFO:     filename                 : 1\n",
      "COMET INFO:     git metadata             : 1\n",
      "COMET INFO:     git-patch (uncompressed) : 1 (53.86 KB)\n",
      "COMET INFO:     installed packages       : 1\n",
      "COMET INFO:     os packages              : 1\n",
      "COMET INFO: ---------------------------\n",
      "COMET WARNING: As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "COMET INFO: Experiment is live on comet.ml https://www.comet.ml/tci/igtc-project/5443c1ded4b649a582d4b1f9dddc49d6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from comet_ml import Experiment\n",
    "experiment = Experiment(\n",
    "    api_key=\"2PoVCksa2Ak6yyjIKOZ7nlzto\",\n",
    "    project_name=\"igtc-project\",\n",
    "    workspace=\"tci\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import collections\n",
    "import json\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_addons as tfa\n",
    "import tensorflow_text as text\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.get_logger().setLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Sep 20 17:39:27 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.142.00   Driver Version: 450.142.00   CUDA Version: 11.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  On   | 00000000:00:1E.0 Off |                    0 |\n",
      "| N/A   36C    P0    24W / 300W |      0MiB / 16160MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"../data\"\n",
    "sub_root_dir = os.path.join(root_dir, \"gt_processed\")\n",
    "images_dir = os.path.join(sub_root_dir, \"images\")\n",
    "tfrecords_dir = os.path.join(sub_root_dir, \"tfrecords\")\n",
    "lp_file = os.path.join(sub_root_dir, \"correct_data.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images: 11400\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "with open(lp_file, \"r\") as f:\n",
    "    annotations = json.load(f)[\"annotations\"]\n",
    "\n",
    "image_path_to_lp = collections.defaultdict(list)\n",
    "\n",
    "for element in annotations:\n",
    "    postocr = f\"{element['postocr']}\"\n",
    "    gt = f\"{element['gt']}\"\n",
    "    image_path = os.path.join(images_dir, element[\"image\"])\n",
    "#     image_path_to_lp[image_path].append(postocr)\n",
    "    image_path_to_lp[image_path].append(gt)\n",
    "\n",
    "\n",
    "image_paths = list(image_path_to_lp.keys())\n",
    "print(f\"Number of images: {len(image_paths)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 9000\n",
    "valid_size = len(image_paths) - train_size\n",
    "lps_per_image = 2\n",
    "train_images_per_file = 3000\n",
    "valid_images_per_file = 800\n",
    "\n",
    "train_image_paths = image_paths[:train_size]\n",
    "num_train_files = int(np.ceil(train_size / train_images_per_file))\n",
    "train_files_prefix = os.path.join(tfrecords_dir, \"train\")\n",
    "\n",
    "valid_image_paths = image_paths[-valid_size:]\n",
    "num_valid_files = int(np.ceil(valid_size / valid_images_per_file))\n",
    "valid_files_prefix = os.path.join(tfrecords_dir, \"valid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.io.gfile.makedirs(tfrecords_dir)\n",
    "\n",
    "\n",
    "def bytes_feature(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "\n",
    "def create_feature(image_path, lp):\n",
    "    feature = {\n",
    "        \"lp\": bytes_feature(lp.encode()),\n",
    "        \"image\": bytes_feature(tf.io.read_file(image_path).numpy()),\n",
    "    }\n",
    "    return tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "\n",
    "\n",
    "def write_tfrecords(file_name, image_paths):\n",
    "    lp_list = []\n",
    "    image_path_list = []\n",
    "    for image_path in image_paths:\n",
    "        lps = image_path_to_lp[image_path]\n",
    "        lp_list.extend(lps)\n",
    "        image_path_list.extend([image_path] * len(lps))\n",
    "    with tf.io.TFRecordWriter(file_name) as writer:\n",
    "        for example_idx in range(len(image_path_list)):\n",
    "            example = create_feature(\n",
    "                image_path_list[example_idx], lp_list[example_idx]\n",
    "            )\n",
    "            writer.write(example.SerializeToString())\n",
    "    return example_idx + 1\n",
    "\n",
    "\n",
    "def write_data(image_paths, num_files, files_prefix, images_per_file):\n",
    "    example_counter = 0\n",
    "    for file_idx in tqdm(range(num_files)):\n",
    "        file_name = files_prefix + \"-%02d.tfrecord\" % (file_idx)\n",
    "        start_idx = images_per_file * file_idx\n",
    "        end_idx = start_idx + images_per_file\n",
    "        example_counter += write_tfrecords(file_name, image_paths[start_idx:end_idx])\n",
    "    return example_counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:02<00:00,  1.10it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00,  4.34it/s]\n"
     ]
    }
   ],
   "source": [
    "train_example_count = write_data(train_image_paths, num_train_files, train_files_prefix, train_images_per_file)\n",
    "valid_example_count = write_data(valid_image_paths, num_valid_files, valid_files_prefix, valid_images_per_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_embeddings(\n",
    "    embeddings, num_projection_layers, projection_dims, dropout_rate\n",
    "):\n",
    "    projected_embeddings = layers.Dense(units=projection_dims)(embeddings)\n",
    "    for _ in range(num_projection_layers):\n",
    "        x = tf.nn.gelu(projected_embeddings)\n",
    "        x = layers.Dense(projection_dims)(x)\n",
    "        x = layers.Dropout(dropout_rate)(x)\n",
    "        x = layers.Add()([projected_embeddings, x])\n",
    "        projected_embeddings = layers.LayerNormalization()(x)\n",
    "    return projected_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vision_encoder(\n",
    "    num_projection_layers, projection_dims, dropout_rate, trainable=False\n",
    "):\n",
    "    xception = keras.applications.Xception(\n",
    "        include_top=False, weights=\"imagenet\", pooling=\"avg\"\n",
    "    )\n",
    "    for layer in xception.layers:\n",
    "        layer.trainable = trainable\n",
    "    inputs = layers.Input(shape=(299, 299, 3), name=\"image_input\")\n",
    "    xception_input = tf.keras.applications.xception.preprocess_input(inputs)\n",
    "    embeddings = xception(xception_input)\n",
    "    outputs = project_embeddings(\n",
    "        embeddings, num_projection_layers, projection_dims, dropout_rate\n",
    "    )\n",
    "    return keras.Model(inputs, outputs, name=\"vision_encoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_text_encoder(\n",
    "    num_projection_layers, projection_dims, dropout_rate, trainable=False\n",
    "):\n",
    "    preprocess = hub.KerasLayer(\n",
    "        \"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/2\",\n",
    "        name=\"text_preprocessing\",\n",
    "    )\n",
    "    bert = hub.KerasLayer(\n",
    "        \"https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1\",\n",
    "        \"bert\",\n",
    "    )\n",
    "    bert.trainable = trainable\n",
    "    inputs = layers.Input(shape=(), dtype=tf.string, name=\"text_input\")\n",
    "    bert_inputs = preprocess(inputs)\n",
    "    embeddings = bert(bert_inputs)[\"pooled_output\"]\n",
    "    outputs = project_embeddings(\n",
    "        embeddings, num_projection_layers, projection_dims, dropout_rate\n",
    "    )\n",
    "    return keras.Model(inputs, outputs, name=\"text_encoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IGTCPreTrainer(keras.Model):\n",
    "    def __init__(self, text_encoder, image_encoder, **kwargs):\n",
    "        super(IGTCPreTrainer, self).__init__(**kwargs)\n",
    "        self.text_encoder = text_encoder\n",
    "        self.image_encoder = image_encoder\n",
    "        self.temp = tf.Variable(1.)\n",
    "        self.loss_tracker = keras.metrics.Mean(name=\"loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.loss_tracker]\n",
    "\n",
    "    def call(self, features, training=False):\n",
    "        lp_embeddings = text_encoder(features[\"lp\"], training=training)\n",
    "        image_embeddings = vision_encoder(features[\"image\"], training=training)\n",
    "        return lp_embeddings, image_embeddings, tf.math.exp(tf.math.scalar_mul(self.temp, tf.math.log(1/0.07)))\n",
    "\n",
    "    def compute_loss(self, lp_embeddings, image_embeddings, logit_scale):\n",
    "        logits = (\n",
    "            tf.matmul(lp_embeddings, image_embeddings, transpose_b=True)\n",
    "            * logit_scale\n",
    "        )\n",
    "        images_similarity = tf.matmul(\n",
    "            image_embeddings, image_embeddings, transpose_b=True\n",
    "        )\n",
    "        lp_similarity = tf.matmul(\n",
    "            lp_embeddings, lp_embeddings, transpose_b=True\n",
    "        )\n",
    "        targets = keras.activations.softmax(\n",
    "            (lp_similarity + images_similarity) / 2\n",
    "        )\n",
    "        lp_loss = keras.losses.categorical_crossentropy(\n",
    "            y_true=targets, y_pred=logits, from_logits=True\n",
    "        )\n",
    "        images_loss = keras.losses.categorical_crossentropy(\n",
    "            y_true=tf.transpose(targets), y_pred=tf.transpose(logits), from_logits=True\n",
    "        )\n",
    "        return (lp_loss + images_loss) / 2\n",
    "\n",
    "    def train_step(self, features):\n",
    "        with tf.GradientTape() as tape:\n",
    "            lp_embeddings, image_embeddings, logit_scale = self(features, training=True)\n",
    "            logit_scale = tf.clip_by_value(logit_scale, clip_value_min=0, clip_value_max=4.6052)\n",
    "            loss = self.compute_loss(lp_embeddings, image_embeddings, logit_scale)\n",
    "        gradients = tape.gradient(loss, self.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
    "        self.loss_tracker.update_state(loss)\n",
    "        return {\"loss\": self.loss_tracker.result()}\n",
    " \n",
    "    def test_step(self, features):\n",
    "        lp_embeddings, image_embeddings, logit_scale = self(features, training=False)\n",
    "        logit_scale = tf.clip_by_value(logit_scale, clip_value_min=0, clip_value_max=4.6052)\n",
    "        loss = self.compute_loss(lp_embeddings, image_embeddings, logit_scale)\n",
    "        self.loss_tracker.update_state(loss)\n",
    "        return {\"loss\": self.loss_tracker.result()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 5\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-20 20:09:22.296712: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-09-20 20:09:22.297947: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2021-09-20 20:09:22.350867: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-20 20:09:22.351852: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:00:1e.0 name: Tesla V100-SXM2-16GB computeCapability: 7.0\n",
      "coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 15.78GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2021-09-20 20:09:22.351886: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-20 20:09:22.354815: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2021-09-20 20:09:22.354887: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "2021-09-20 20:09:22.356623: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2021-09-20 20:09:22.357038: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2021-09-20 20:09:22.359102: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-09-20 20:09:22.359914: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "2021-09-20 20:09:22.360147: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-09-20 20:09:22.360311: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-20 20:09:22.361373: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-20 20:09:22.362293: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2021-09-20 20:09:22.363233: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-09-20 20:09:22.363364: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-20 20:09:22.364305: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:00:1e.0 name: Tesla V100-SXM2-16GB computeCapability: 7.0\n",
      "coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 15.78GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2021-09-20 20:09:22.364337: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-20 20:09:22.364370: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2021-09-20 20:09:22.364400: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "2021-09-20 20:09:22.364429: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2021-09-20 20:09:22.364457: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2021-09-20 20:09:22.364486: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-09-20 20:09:22.364515: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "2021-09-20 20:09:22.364543: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-09-20 20:09:22.364632: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-20 20:09:22.365651: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-20 20:09:22.366557: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2021-09-20 20:09:22.366609: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-20 20:09:23.145479: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-09-20 20:09:23.145519: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2021-09-20 20:09:23.145529: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2021-09-20 20:09:23.145804: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-20 20:09:23.146812: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-20 20:09:23.147785: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-20 20:09:23.148722: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14760 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:1e.0, compute capability: 7.0)\n",
      "2021-09-20 20:09:27.649151: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2021-09-20 20:09:27.669201: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2300010000 Hz\n",
      "COMET ERROR: Failed to extract parameters from Optimizer.init()\n"
     ]
    }
   ],
   "source": [
    "vision_encoder = create_vision_encoder(\n",
    "    num_projection_layers=1, projection_dims=256, dropout_rate=0.2)\n",
    "text_encoder = create_text_encoder(\n",
    "    num_projection_layers=1, projection_dims=256, dropout_rate=0.1)\n",
    "pretrainer = IGTCPreTrainer(text_encoder, vision_encoder)\n",
    "pretrainer.compile(\n",
    "    optimizer=tfa.optimizers.AdamW(learning_rate=0.001, weight_decay=0.001)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_fn(sample):\n",
    "    features = tf.io.parse_single_example(\n",
    "        sample,\n",
    "        {\n",
    "           \"lp\": tf.io.FixedLenFeature([], dtype=tf.string),\n",
    "           \"image\": tf.io.FixedLenFeature([], dtype=tf.string)\n",
    "        }\n",
    "    )\n",
    "    features['image'] = tf.io.decode_jpeg(\n",
    "        features['image'], channels=3\n",
    "    )\n",
    "    return features\n",
    "    \n",
    "\n",
    "def fetch_dataset_tfrecord(string_pattern, batch_size, shuffle_size):\n",
    "    return (\n",
    "        tf.data.TFRecordDataset(\n",
    "            tf.data.Dataset.list_files(string_pattern))\n",
    "        .map(decode_fn, num_parallel_calls=8)\n",
    "        .shuffle(shuffle_size)\n",
    "        .batch(batch_size)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = fetch_dataset_tfrecord(\n",
    "    os.path.join(tfrecords_dir, \"train-*.tfrecord\"),\n",
    "    batch_size,\n",
    "    train_size\n",
    ")\n",
    "valid_dataset = fetch_dataset_tfrecord(\n",
    "    os.path.join(tfrecords_dir, \"valid-*.tfrecord\"),\n",
    "    batch_size,\n",
    "    valid_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET WARNING: tensorflow datasets are not currently supported for gradient and activation auto-logging\n",
      "COMET WARNING: An unknown exception happened in Keras callback on_train_begin; ignoring\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-19 12:17:52.492180: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2021-09-19 12:17:53.319774: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "2021-09-19 12:17:53.757498: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 109s 1s/step - loss: 34.1872 - val_loss: 8.7790\n",
      "Epoch 2/5\n",
      "71/71 [==============================] - 96s 1s/step - loss: 9.6586 - val_loss: 5.5656\n",
      "Epoch 3/5\n",
      "71/71 [==============================] - 97s 1s/step - loss: 5.7642 - val_loss: 4.9615\n",
      "Epoch 4/5\n",
      "71/71 [==============================] - 96s 1s/step - loss: 5.0905 - val_loss: 4.9091\n",
      "Epoch 5/5\n",
      "71/71 [==============================] - 96s 1s/step - loss: 4.9306 - val_loss: 4.8895\n"
     ]
    }
   ],
   "source": [
    "reduce_learningRate = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\", factor=0.2, patience=3\n",
    ")\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath='clipPretrained_model_{epoch:02d}-{val_loss:.2f}.h5')\n",
    "\n",
    "history = pretrainer.fit(\n",
    "    train_dataset,\n",
    "    epochs=num_epochs,\n",
    "    validation_data=valid_dataset,\n",
    "    callbacks=[reduce_learningRate, model_checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history[\"loss\"])\n",
    "plt.plot(history.history[\"val_loss\"])\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend([\"train\", \"valid\"], loc=\"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "SavedModel file does not exist at: experiments/clipPretrained_model_05-4.89.h5/{saved_model.pbtxt|saved_model.pb}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3560/182995719.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpretrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'experiments/clipPretrained_model_05-4.89.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/imageguidedtextcorrection-7soGK06H-py3.8/lib/python3.8/site-packages/tensorflow/python/keras/saving/save.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[1;32m    209\u001b[0m       \u001b[0mfilepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath_to_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0mloader_impl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_saved_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msaved_model_load\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/imageguidedtextcorrection-7soGK06H-py3.8/lib/python3.8/site-packages/tensorflow/python/saved_model/loader_impl.py\u001b[0m in \u001b[0;36mparse_saved_model\u001b[0;34m(export_dir)\u001b[0m\n\u001b[1;32m    109\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot parse file %s: %s.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpath_to_pbtxt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m     raise IOError(\"SavedModel file does not exist at: %s/{%s|%s}\" %\n\u001b[0m\u001b[1;32m    112\u001b[0m                   (export_dir,\n\u001b[1;32m    113\u001b[0m                    \u001b[0mconstants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSAVED_MODEL_FILENAME_PBTXT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: SavedModel file does not exist at: experiments/clipPretrained_model_05-4.89.h5/{saved_model.pbtxt|saved_model.pb}"
     ]
    }
   ],
   "source": [
    "pretrainer = tf.keras.models.load_model('experiments/clipPretrained_model_05-4.89.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: {image: (None, None, None, 3), lp: (None,)}, types: {image: tf.uint8, lp: tf.string}>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
